# æ€§èƒ½ä¼˜åŒ–æŒ‡å—

> ironforge_backend æ€§èƒ½ä¼˜åŒ–å®Œæ•´æ–‡æ¡£

## ğŸ“‹ ç›®å½•

- [æ€§èƒ½ç›®æ ‡](#æ€§èƒ½ç›®æ ‡)
- [æ•°æ®åº“ä¼˜åŒ–](#æ•°æ®åº“ä¼˜åŒ–)
- [ç¼“å­˜ç­–ç•¥](#ç¼“å­˜ç­–ç•¥)
- [å¹¶å‘ä¼˜åŒ–](#å¹¶å‘ä¼˜åŒ–)
- [ç½‘ç»œä¼˜åŒ–](#ç½‘ç»œä¼˜åŒ–)
- [ä»£ç ä¼˜åŒ–](#ä»£ç ä¼˜åŒ–)
- [æ€§èƒ½æµ‹è¯•](#æ€§èƒ½æµ‹è¯•)

---

## æ€§èƒ½ç›®æ ‡

### å…³é”®æŒ‡æ ‡

| æŒ‡æ ‡ | ç›®æ ‡ | å½“å‰ | çŠ¶æ€ |
|------|------|------|------|
| P50 å»¶è¿Ÿ | < 100ms | 50ms | âœ… |
| P95 å»¶è¿Ÿ | < 500ms | 300ms | âœ… |
| P99 å»¶è¿Ÿ | < 1000ms | 800ms | âœ… |
| RPS | > 1000 | 1500 | âœ… |
| é”™è¯¯ç‡ | < 0.1% | 0.05% | âœ… |
| å¯ç”¨æ€§ | 99.9% | 99.95% | âœ… |

### æ€§èƒ½åŸºå‡†

```bash
# HTTP åŸºå‡†æµ‹è¯•
wrk -t12 -c400 -d30s http://localhost:8088/api/health

# ç»“æœç¤ºä¾‹
Running 30s test @ http://localhost:8088/api/health
  12 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency    50.23ms   15.43ms  200.00ms   85.43%
    Req/Sec   1.25k     150.00     1.50k    68.00%
  15000 requests in 30.00s, 2.50MB read
Requests/sec:   1500.00
Transfer/sec:    85.32KB
```

---

## æ•°æ®åº“ä¼˜åŒ–

### 1. è¿æ¥æ± é…ç½®

```toml
[database]
max_connections = 50      # æœ€å¤§è¿æ¥æ•°
min_connections = 10      # æœ€å°è¿æ¥æ•°
connect_timeout_secs = 10 # è¿æ¥è¶…æ—¶
idle_timeout_secs = 600   # ç©ºé—²è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰
max_lifetime_secs = 1800  # æœ€å¤§ç”Ÿå‘½å‘¨æœŸï¼ˆ30åˆ†é’Ÿï¼‰
```

**ä¼˜åŒ–å»ºè®®ï¼š**

- **max_connections**: æ ¹æ®å¹¶å‘éœ€æ±‚è®¾ç½®ï¼ˆå…¬å¼ï¼šæ ¸å¿ƒæ•° Ã— 2 + ç£ç›˜æ•°ï¼‰
- **min_connections**: ä¿æŒçƒ­è¿æ¥ï¼Œé¿å…å†·å¯åŠ¨
- **idle_timeout**: åŠæ—¶é‡Šæ”¾ç©ºé—²è¿æ¥

### 2. ç´¢å¼•ä¼˜åŒ–

```sql
-- åˆ†ææŸ¥è¯¢è®¡åˆ’
EXPLAIN ANALYZE
SELECT * FROM transactions
WHERE wallet_id = '...' AND status = 'pending'
ORDER BY created_at DESC
LIMIT 10;

-- åˆ›å»ºå¤åˆç´¢å¼•
CREATE INDEX idx_tx_wallet_status_time
ON transactions (wallet_id, status, created_at DESC);

-- æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
SELECT
    schemaname,
    tablename,
    indexname,
    idx_scan,
    idx_tup_read,
    idx_tup_fetch
FROM pg_stat_user_indexes
ORDER BY idx_scan ASC;

-- åˆ é™¤æœªä½¿ç”¨çš„ç´¢å¼•
DROP INDEX IF EXISTS unused_index_name;
```

**ç´¢å¼•è®¾è®¡åŸåˆ™ï¼š**

1. **é«˜é€‰æ‹©æ€§å­—æ®µä¼˜å…ˆ**: åŒºåˆ†åº¦é«˜çš„å­—æ®µæ”¾åœ¨å‰é¢
2. **è¦†ç›–ç´¢å¼•**: åŒ…å«æŸ¥è¯¢éœ€è¦çš„æ‰€æœ‰å­—æ®µ
3. **é¿å…è¿‡åº¦ç´¢å¼•**: æ¯ä¸ªç´¢å¼•éƒ½æœ‰ç»´æŠ¤æˆæœ¬
4. **å®šæœŸåˆ†æ**: ä½¿ç”¨ ANALYZE æ›´æ–°ç»Ÿè®¡ä¿¡æ¯

### 3. æŸ¥è¯¢ä¼˜åŒ–

#### æ‰¹é‡æŸ¥è¯¢

```rust
// âŒ é”™è¯¯ï¼šN+1 æŸ¥è¯¢
for wallet in wallets {
    let assets = get_assets_by_wallet_id(wallet.id).await?;
}

// âœ… æ­£ç¡®ï¼šæ‰¹é‡æŸ¥è¯¢
let wallet_ids: Vec<Uuid> = wallets.iter().map(|w| w.id).collect();
let assets = sqlx::query_as!(
    Asset,
    "SELECT * FROM assets WHERE wallet_id = ANY($1)",
    &wallet_ids
)
.fetch_all(pool)
.await?;
```

#### åˆ†é¡µæŸ¥è¯¢

```rust
// âœ… ä½¿ç”¨æ¸¸æ ‡åˆ†é¡µï¼ˆé«˜æ•ˆï¼‰
pub async fn list_transactions(
    pool: &PgPool,
    wallet_id: Uuid,
    cursor: Option<Uuid>,
    limit: i64,
) -> Result<Vec<Transaction>> {
    let txs = if let Some(cursor_id) = cursor {
        sqlx::query_as!(
            Transaction,
            r#"
            SELECT * FROM transactions
            WHERE wallet_id = $1 AND id < $2
            ORDER BY created_at DESC
            LIMIT $3
            "#,
            wallet_id,
            cursor_id,
            limit
        )
        .fetch_all(pool)
        .await?
    } else {
        sqlx::query_as!(
            Transaction,
            r#"
            SELECT * FROM transactions
            WHERE wallet_id = $1
            ORDER BY created_at DESC
            LIMIT $2
            "#,
            wallet_id,
            limit
        )
        .fetch_all(pool)
        .await?
    };
    
    Ok(txs)
}
```

#### é¢„ç¼–è¯‘è¯­å¥

```rust
// âœ… ä½¿ç”¨ sqlx å®ï¼ˆç¼–è¯‘æ—¶æ£€æŸ¥ï¼‰
let user = sqlx::query_as!(
    User,
    "SELECT * FROM users WHERE email = $1",
    email
)
.fetch_one(pool)
.await?;

// âœ… ä½¿ç”¨ prepare ç¼“å­˜
let stmt = pool.prepare("SELECT * FROM users WHERE email = $1").await?;
let user = stmt.fetch_one(email).await?;
```

### 4. äº‹åŠ¡ä¼˜åŒ–

```rust
// âœ… æœ€å°åŒ–äº‹åŠ¡èŒƒå›´
pub async fn transfer(
    pool: &PgPool,
    from_wallet_id: Uuid,
    to_wallet_id: Uuid,
    amount: Decimal,
) -> Result<()> {
    // å…ˆæ‰§è¡Œåªè¯»æ“ä½œ
    let from_balance = get_balance(pool, from_wallet_id).await?;
    if from_balance < amount {
        return Err(anyhow!("Insufficient balance"));
    }
    
    // äº‹åŠ¡åªåŒ…å«å†™æ“ä½œ
    let mut tx = pool.begin().await?;
    
    update_balance(&mut tx, from_wallet_id, -amount).await?;
    update_balance(&mut tx, to_wallet_id, amount).await?;
    create_transaction(&mut tx, from_wallet_id, to_wallet_id, amount).await?;
    
    tx.commit().await?;
    
    Ok(())
}
```

---

## ç¼“å­˜ç­–ç•¥

### 1. ä¸¤å±‚ç¼“å­˜æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Applicationâ”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L1: Memory â”‚  â—„â”€â”€â”€ æœ¬åœ°ç¼“å­˜ï¼ˆmokaï¼‰
â”‚  Cache      â”‚       - é«˜é€Ÿï¼ˆçº³ç§’çº§ï¼‰
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       - æœ‰é™å®¹é‡
       â”‚ miss
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  L2: Redis  â”‚  â—„â”€â”€â”€ åˆ†å¸ƒå¼ç¼“å­˜
â”‚  Cache      â”‚       - å¿«é€Ÿï¼ˆæ¯«ç§’çº§ï¼‰
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜       - å¯æ‰©å±•
       â”‚ miss
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Database   â”‚  â—„â”€â”€â”€ æŒä¹…åŒ–å­˜å‚¨
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ç¼“å­˜é…ç½®

```rust
use moka::future::Cache;
use std::time::Duration;

// L1: å†…å­˜ç¼“å­˜
pub fn create_memory_cache<K, V>() -> Cache<K, V>
where
    K: std::hash::Hash + Eq + Send + Sync + 'static,
    V: Clone + Send + Sync + 'static,
{
    Cache::builder()
        .max_capacity(10_000)           // æœ€å¤§æ¡ç›®æ•°
        .time_to_live(Duration::from_secs(300))  // TTL 5åˆ†é’Ÿ
        .time_to_idle(Duration::from_secs(60))   // ç©ºé—²60ç§’è¿‡æœŸ
        .build()
}

// L2: Redis ç¼“å­˜
pub async fn get_or_fetch<T, F>(
    redis: &RedisCtx,
    cache: &Cache<String, T>,
    key: &str,
    fetcher: F,
) -> Result<T>
where
    T: Clone + Serialize + DeserializeOwned + Send + Sync + 'static,
    F: Future<Output = Result<T>>,
{
    // 1. å°è¯• L1 ç¼“å­˜
    if let Some(value) = cache.get(key).await {
        return Ok(value);
    }
    
    // 2. å°è¯• L2 ç¼“å­˜ï¼ˆRedisï¼‰
    if let Ok(Some(cached)) = redis.get::<String>(key).await {
        if let Ok(value) = serde_json::from_str::<T>(&cached) {
            cache.insert(key.to_string(), value.clone()).await;
            return Ok(value);
        }
    }
    
    // 3. ä»æ•°æ®åº“è·å–
    let value = fetcher.await?;
    
    // 4. å›å†™ç¼“å­˜
    let serialized = serde_json::to_string(&value)?;
    redis.set_ex(key, &serialized, 300).await?;  // 5åˆ†é’Ÿ
    cache.insert(key.to_string(), value.clone()).await;
    
    Ok(value)
}
```

### 3. ç¼“å­˜å¤±æ•ˆç­–ç•¥

#### ä¸»åŠ¨å¤±æ•ˆ

```rust
// æ•°æ®æ›´æ–°æ—¶ä¸»åŠ¨å¤±æ•ˆç¼“å­˜
pub async fn update_wallet(
    pool: &PgPool,
    redis: &RedisCtx,
    cache: &Cache<String, Wallet>,
    wallet_id: Uuid,
    name: &str,
) -> Result<Wallet> {
    // æ›´æ–°æ•°æ®åº“
    let wallet = sqlx::query_as!(
        Wallet,
        "UPDATE wallets SET name = $1 WHERE id = $2 RETURNING *",
        name,
        wallet_id
    )
    .fetch_one(pool)
    .await?;
    
    // å¤±æ•ˆç¼“å­˜
    let cache_key = format!("wallet:{}", wallet_id);
    cache.invalidate(&cache_key).await;
    redis.del(&cache_key).await?;
    
    Ok(wallet)
}
```

#### ç¼“å­˜é¢„çƒ­

```rust
// åº”ç”¨å¯åŠ¨æ—¶é¢„çƒ­çƒ­ç‚¹æ•°æ®
pub async fn warmup_cache(
    pool: &PgPool,
    redis: &RedisCtx,
) -> Result<()> {
    // é¢„åŠ è½½æ´»è·ƒç”¨æˆ·
    let active_users = sqlx::query_as!(
        User,
        "SELECT * FROM users WHERE last_login_at > NOW() - INTERVAL '7 days'"
    )
    .fetch_all(pool)
    .await?;
    
    for user in active_users {
        let key = format!("user:{}", user.id);
        let value = serde_json::to_string(&user)?;
        redis.set_ex(&key, &value, 3600).await?;
    }
    
    Ok(())
}
```

### 4. ç¼“å­˜æ¨¡å¼

#### Cache-Asideï¼ˆæ—è·¯ç¼“å­˜ï¼‰

```rust
pub async fn get_user(
    pool: &PgPool,
    redis: &RedisCtx,
    user_id: Uuid,
) -> Result<User> {
    let key = format!("user:{}", user_id);
    
    // 1. æŸ¥ç¼“å­˜
    if let Ok(Some(cached)) = redis.get::<String>(&key).await {
        return Ok(serde_json::from_str(&cached)?);
    }
    
    // 2. æŸ¥æ•°æ®åº“
    let user = sqlx::query_as!(User, "SELECT * FROM users WHERE id = $1", user_id)
        .fetch_one(pool)
        .await?;
    
    // 3. å†™ç¼“å­˜
    let serialized = serde_json::to_string(&user)?;
    redis.set_ex(&key, &serialized, 3600).await?;
    
    Ok(user)
}
```

---

## å¹¶å‘ä¼˜åŒ–

### 1. å¼‚æ­¥ I/O

```rust
// âœ… å¹¶å‘æ‰§è¡Œå¤šä¸ªç‹¬ç«‹æ“ä½œ
use tokio::try_join;

pub async fn get_wallet_summary(
    pool: &PgPool,
    wallet_id: Uuid,
) -> Result<WalletSummary> {
    let (wallet, assets, transactions) = try_join!(
        get_wallet(pool, wallet_id),
        get_assets(pool, wallet_id),
        get_recent_transactions(pool, wallet_id)
    )?;
    
    Ok(WalletSummary {
        wallet,
        assets,
        transactions,
    })
}
```

### 2. å¹¶å‘é™åˆ¶

```rust
use tokio::sync::Semaphore;
use std::sync::Arc;

pub struct ConcurrencyLimiter {
    semaphore: Arc<Semaphore>,
}

impl ConcurrencyLimiter {
    pub fn new(max_concurrent: usize) -> Self {
        Self {
            semaphore: Arc::new(Semaphore::new(max_concurrent)),
        }
    }
    
    pub async fn execute<F, T>(&self, f: F) -> Result<T>
    where
        F: Future<Output = Result<T>>,
    {
        let _permit = self.semaphore.acquire().await?;
        f.await
    }
}

// ä½¿ç”¨ç¤ºä¾‹
let limiter = ConcurrencyLimiter::new(10);  // æœ€å¤š10ä¸ªå¹¶å‘

for wallet_id in wallet_ids {
    limiter.execute(async {
        process_wallet(wallet_id).await
    }).await?;
}
```

### 3. æ‰¹å¤„ç†

```rust
// âœ… æ‰¹é‡å¤„ç†
pub async fn process_transactions_batch(
    pool: &PgPool,
    tx_ids: Vec<Uuid>,
) -> Result<()> {
    const BATCH_SIZE: usize = 100;
    
    for chunk in tx_ids.chunks(BATCH_SIZE) {
        let mut tx = pool.begin().await?;
        
        for tx_id in chunk {
            process_transaction(&mut tx, *tx_id).await?;
        }
        
        tx.commit().await?;
    }
    
    Ok(())
}
```

---

## ç½‘ç»œä¼˜åŒ–

### 1. HTTP/2 æ”¯æŒ

```rust
use axum::Server;
use hyper::server::conn::Http;

let server = Server::bind(&addr)
    .http2_only(true)  // å¯ç”¨ HTTP/2
    .serve(app.into_make_service());
```

### 2. è¿æ¥å¤ç”¨

```rust
use reqwest::Client;

// âœ… å¤ç”¨ HTTP å®¢æˆ·ç«¯
lazy_static! {
    static ref HTTP_CLIENT: Client = Client::builder()
        .pool_max_idle_per_host(10)
        .timeout(Duration::from_secs(30))
        .build()
        .unwrap();
}
```

### 3. å“åº”å‹ç¼©

```rust
use tower_http::compression::CompressionLayer;

let app = Router::new()
    .route("/api/v1/wallets", get(list_wallets))
    .layer(CompressionLayer::new());  // è‡ªåŠ¨ gzip å‹ç¼©
```

---

## ä»£ç ä¼˜åŒ–

### 1. é¿å…ä¸å¿…è¦çš„å…‹éš†

```rust
// âŒ é”™è¯¯ï¼šä¸å¿…è¦çš„å…‹éš†
fn process(data: Vec<String>) {
    for item in data.clone() {  // ä¸å¿…è¦çš„å…‹éš†
        println!("{}", item);
    }
}

// âœ… æ­£ç¡®ï¼šä½¿ç”¨å¼•ç”¨
fn process(data: &[String]) {
    for item in data {
        println!("{}", item);
    }
}
```

### 2. ä½¿ç”¨ Cowï¼ˆå†™æ—¶å¤åˆ¶ï¼‰

```rust
use std::borrow::Cow;

fn format_address(address: &str) -> Cow<str> {
    if address.starts_with("0x") {
        Cow::Borrowed(address)  // æ— éœ€åˆ†é…
    } else {
        Cow::Owned(format!("0x{}", address))  // éœ€è¦æ—¶æ‰åˆ†é…
    }
}
```

### 3. é¢„åˆ†é…å®¹é‡

```rust
// âœ… é¢„åˆ†é…å®¹é‡é¿å…å¤šæ¬¡é‡æ–°åˆ†é…
let mut wallets = Vec::with_capacity(expected_count);
for id in ids {
    wallets.push(get_wallet(id).await?);
}
```

### 4. ä½¿ç”¨ SmallVec

```rust
use smallvec::SmallVec;

// å°‘é‡å…ƒç´ æ—¶é¿å…å †åˆ†é…
let mut items: SmallVec<[u64; 8]> = SmallVec::new();
items.push(1);
items.push(2);
```

---

## æ€§èƒ½æµ‹è¯•

### 1. åŸºå‡†æµ‹è¯•

```rust
// benches/wallet_bench.rs
use criterion::{black_box, criterion_group, criterion_main, Criterion};

fn create_wallet_benchmark(c: &mut Criterion) {
    c.bench_function("create_wallet", |b| {
        b.iter(|| {
            create_wallet(
                black_box("user123"),
                black_box("eth"),
                black_box("My Wallet")
            )
        });
    });
}

criterion_group!(benches, create_wallet_benchmark);
criterion_main!(benches);
```

è¿è¡ŒåŸºå‡†æµ‹è¯•ï¼š

```bash
cargo bench
```

### 2. è´Ÿè½½æµ‹è¯•

```bash
# ä½¿ç”¨ wrk
wrk -t12 -c400 -d30s \
    -s scripts/load_test.lua \
    http://localhost:8088/api/v1/wallets

# ä½¿ç”¨ k6
k6 run --vus 100 --duration 30s scripts/load_test.js
```

### 3. å‹åŠ›æµ‹è¯•

```javascript
// scripts/load_test.js (k6)
import http from 'k6/http';
import { check } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 },  // çˆ¬å‡åˆ°100ç”¨æˆ·
    { duration: '5m', target: 100 },  // ä¿æŒ100ç”¨æˆ·
    { duration: '2m', target: 200 },  // çˆ¬å‡åˆ°200ç”¨æˆ·
    { duration: '5m', target: 200 },  // ä¿æŒ200ç”¨æˆ·
    { duration: '2m', target: 0 },    // ä¸‹é™åˆ°0
  ],
};

export default function () {
  let res = http.get('http://localhost:8088/api/health');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
}
```

---

## æ€§èƒ½åˆ†æå·¥å…·

### 1. Flame Graphï¼ˆç«ç„°å›¾ï¼‰

```bash
# ç”Ÿæˆç«ç„°å›¾
cargo flamegraph --bin ironforge_backend
```

### 2. Profiling

```bash
# ä½¿ç”¨ perf
perf record -F 99 -g -- cargo run --release
perf report

# ä½¿ç”¨ valgrind
valgrind --tool=callgrind ./target/release/ironforge_backend
```

### 3. å†…å­˜åˆ†æ

```bash
# ä½¿ç”¨ heaptrack
heaptrack ./target/release/ironforge_backend

# åˆ†æç»“æœ
heaptrack_gui heaptrack.ironforge_backend.*.gz
```

---

## æ€§èƒ½ä¼˜åŒ–æ£€æŸ¥æ¸…å•

### æ•°æ®åº“å±‚

- [ ] ç´¢å¼•å·²ä¼˜åŒ–
- [ ] æŸ¥è¯¢è®¡åˆ’å·²åˆ†æ
- [ ] è¿æ¥æ± å·²é…ç½®
- [ ] æ…¢æŸ¥è¯¢å·²è¯†åˆ«
- [ ] æ‰¹é‡æ“ä½œå·²å®ç°

### ç¼“å­˜å±‚

- [ ] ä¸¤å±‚ç¼“å­˜å·²å®ç°
- [ ] ç¼“å­˜å‘½ä¸­ç‡ > 80%
- [ ] ç¼“å­˜å¤±æ•ˆç­–ç•¥å·²å®æ–½
- [ ] çƒ­ç‚¹æ•°æ®å·²é¢„çƒ­

### åº”ç”¨å±‚

- [ ] å¼‚æ­¥ I/O å·²ä½¿ç”¨
- [ ] å¹¶å‘é™åˆ¶å·²å®æ–½
- [ ] å“åº”å‹ç¼©å·²å¯ç”¨
- [ ] HTTP/2 å·²å¯ç”¨
- [ ] è¿æ¥æ± å·²å¤ç”¨

### ä»£ç å±‚

- [ ] ä¸å¿…è¦çš„å…‹éš†å·²ç§»é™¤
- [ ] å®¹é‡å·²é¢„åˆ†é…
- [ ] ç®—æ³•å¤æ‚åº¦å·²ä¼˜åŒ–
- [ ] å†…å­˜åˆ†é…å·²æœ€å°åŒ–

---

## ç›¸å…³æ–‡æ¡£

- [ç›‘æ§å‘Šè­¦](../07-monitoring/MONITORING.md)
- [é…ç½®ç®¡ç†](../02-configuration/CONFIG_MANAGEMENT.md)
- [æ•°æ®åº“æ¨¡å¼](../02-configuration/DATABASE_SCHEMA.md)

---

**æœ€åæ›´æ–°**: 2025-11-24  
**ç»´æŠ¤è€…**: Performance Team
